{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5df89252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import time\n",
    "from time import time\n",
    "from time import sleep\n",
    "from scipy.io.wavfile import write\n",
    "import argparse as ap\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import uuid\n",
    "import redis\n",
    "import psutil\n",
    "# import myConnection as mc\n",
    "from datetime import datetime\n",
    "import argparse as ap\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60b549b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir('./datasets/dsl_data/')\n",
    "except:\n",
    "    print(\"\")\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46591eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ap.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--resolution', default=8000, type=int, help=\"Resolution for capturing audio\")\n",
    "# blocksize\n",
    "#parser.add_argument('--blocksize', default=32000, type=int, help=\"Blocksize for captured audio, change only if you previously changed\")\n",
    "parser.add_argument('--downsampling_rate', default=8000, type=int, help=\"Resolution for capturing audio\")\n",
    "parser.add_argument('--device', default=0, type=int, help=\"Default device is 0, change for others\")\n",
    "\n",
    "\n",
    "parser.add_argument('--output_directory', default='./AudioFiles',type=str, help='Used to specify output folder')\n",
    "\n",
    "\n",
    "args = parser.parse_args(['--device','14','--resolution','8000' ])\n",
    "#args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5459695",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocksize = 4 * args.resolution\n",
    "LABELS = ['change languagenone', 'activatemusic', 'deactivatelights', 'increasevolume', 'decreasevolume', 'increaseheat', 'decreaseheat', 'nannan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c543c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['change languagenone', 'activatemusic', 'deactivatelights', 'increasevolume', 'decreasevolume', 'increaseheat', 'decreaseheat', 'nannan']\n"
     ]
    }
   ],
   "source": [
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07481e54",
   "metadata": {},
   "source": [
    "# Necessary preprocessing args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9af86cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length_in_s = 0.04#0.032*2 # /2 for resnet18\n",
    "frame_step_in_s  = frame_length_in_s#frame_length_in_s\n",
    "\n",
    "PREPROCESSING_ARGS = {\n",
    "    'downsampling_rate': args.resolution,\n",
    "    'frame_length_in_s': frame_length_in_s,\n",
    "    'frame_step_in_s': frame_step_in_s,\n",
    "}\n",
    "\n",
    "num_mel_bins = (int) ((args.resolution - args.resolution * PREPROCESSING_ARGS['frame_length_in_s'])/(args.resolution*PREPROCESSING_ARGS['frame_step_in_s']))+1\n",
    "# print(num_mel_bins)\n",
    "\n",
    "PREPROCESSING_ARGS = {\n",
    "    **PREPROCESSING_ARGS,\n",
    "    'num_mel_bins': num_mel_bins,\n",
    "    'lower_frequency': 20,   #40\n",
    "    'upper_frequency': args.resolution/2, #4000\n",
    "}\n",
    "\n",
    "downsampling_rate = PREPROCESSING_ARGS['downsampling_rate']\n",
    "sampling_rate_int64 = tf.cast(downsampling_rate, tf.int64)\n",
    "frame_length = int(downsampling_rate * PREPROCESSING_ARGS['frame_length_in_s'])\n",
    "#print(\"Frame_length: {}\".format(frame_length))\n",
    "frame_step = int(downsampling_rate * PREPROCESSING_ARGS['frame_step_in_s'])\n",
    "#print(\"Frame_length: {}\".format(frame_step))\n",
    "num_spectrogram_bins = frame_length // 2 + 1\n",
    "num_mel_bins = PREPROCESSING_ARGS['num_mel_bins']\n",
    "lower_frequency = PREPROCESSING_ARGS['lower_frequency']\n",
    "upper_frequency = PREPROCESSING_ARGS['upper_frequency']\n",
    "\n",
    "linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "    num_mel_bins=num_mel_bins,\n",
    "    num_spectrogram_bins=num_spectrogram_bins,\n",
    "    sample_rate=downsampling_rate,\n",
    "    lower_edge_hertz=lower_frequency,\n",
    "    upper_edge_hertz=upper_frequency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6351949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"model_24\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=f'./tflite_models/{modelName}.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41a9b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_from_numpy(indata):\n",
    "    indata = tf.convert_to_tensor(indata, dtype=tf.float32)\n",
    "    #print(\"Shape of indata: \",tf.reduce_max(indata))\n",
    "    indata = 2 * ((indata + 32768) / (32767 + 32768)) -1\n",
    "    indata = tf.squeeze(indata)\n",
    "    #print(\"After of indata: \",tf.reduce_max(indata))\n",
    "    return indata\n",
    "\n",
    "def get_spectrogram(indata, frame_length_in_s, frame_step_in_s):\n",
    "    data = get_audio_from_numpy(indata)\n",
    "    \n",
    "    sampling_rate_float32 = tf.cast(args.downsampling_rate, tf.float32)\n",
    "    frame_length = int(frame_length_in_s * sampling_rate_float32)\n",
    "    frame_step = int(frame_step_in_s * sampling_rate_float32)\n",
    "\n",
    "    stft = tf.signal.stft(\n",
    "        data,\n",
    "        frame_length=frame_length,\n",
    "        frame_step=frame_step,\n",
    "        fft_length=frame_length\n",
    "    )\n",
    "    spectrogram = tf.abs(stft)\n",
    "\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7549592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d449f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prediction_as_mqtt(predicted_label):\n",
    "    #print(type(predicted_label))\n",
    "    #print(predicted_label.shape)\n",
    "    #print(predicted_label)\n",
    "    print(\"MAX: \")\n",
    "    print(predicted_label.max())\n",
    "    index = ( np.where(predicted_label == predicted_label.max() )  )\n",
    "    index = index[0][0]\n",
    "    print(index)\n",
    "    print(LABELS[index])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d33bf7",
   "metadata": {},
   "source": [
    "print(LABELS[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2fd3fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_on_indata(indata):\n",
    "    frame_length_in_s = 0.04\n",
    "    frame_step_in_s   = frame_length_in_s\n",
    "    global state\n",
    "    audio = get_audio_from_numpy(indata)\n",
    "    \n",
    "    frame_length = int(frame_length_in_s * args.resolution)\n",
    "    frame_step = int(frame_step_in_s * args.resolution)\n",
    "    stft = tf.signal.stft(\n",
    "        audio,\n",
    "        frame_length=frame_length,\n",
    "        frame_step=frame_step,\n",
    "        fft_length=frame_length\n",
    "    )\n",
    "    \n",
    "    spectrogram = tf.abs(stft)\n",
    "    \n",
    "    mel_spectrogram = tf.matmul(spectrogram, linear_to_mel_weight_matrix)\n",
    "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, 0)  # batch axis\n",
    "    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, -1)  # channel axis\n",
    "    mfcss = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "    #print(\"Shape \",input_details[0])\n",
    "    interpreter.set_tensor(input_details[0]['index'], mfcss)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    print(\"change languagenone\",output[0][0]*100,\"%\")\n",
    "    print(\"activatemusic\",output[0][1]*100,\"%\")\n",
    "    print(\"deactivatelights\",output[0][2]*100,\"%\")\n",
    "    print(\"increasevolume\",output[0][3]*100,\"%\")\n",
    "    print(\"decreasevolume\",output[0][4]*100,\"%\")\n",
    "    print(\"increaseheat\",output[0][5]*100,\"%\")\n",
    "    print(\"decreaseheat\",output[0][6]*100,\"%\")\n",
    "    #print(\"nannan\",output[0][7]*100,\"%\")\n",
    "    \n",
    "    send_prediction_as_mqtt(output[0])\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f469c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = sd.query_devices()\n",
    "device = 0\n",
    "\n",
    "for value in values:\n",
    "    if value['name'] == 'default':\n",
    "        device = value['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddeb2816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(indata, frames, callback_time, status):\n",
    "    timestamp = time()\n",
    "    global state\n",
    "    global mac_address\n",
    "    #if is_silence(indata) == 0 :\n",
    "        #calculate next step of FSM!\n",
    "    prediction_on_indata(indata)\n",
    "    print(\"Elapsed time: \",time()-timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91ebee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['change languagenone', 'activatemusic', 'deactivatelights', 'increasevolume', 'decreasevolume', 'increaseheat', 'decreaseheat', 'nannan']\n"
     ]
    }
   ],
   "source": [
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d33d3",
   "metadata": {},
   "source": [
    "def main():\n",
    "\n",
    "    #print(LABELS)\n",
    "    while True:\n",
    "        with sd.InputStream(device=args.device, channels=1, dtype='int16', samplerate=args.resolution, blocksize=blocksize, callback=callback):\n",
    "            print(\"\") # to print a new line, improving readability in the terminal\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f127f79",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "275c126c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test area\n",
      "Prediction for ./Train_Dataset_Truncated/0_change languagenone.wav\n",
      "change languagenone 99.99960660934448 %\n",
      "activatemusic 9.462366445944781e-08 %\n",
      "deactivatelights 1.3945601617937342e-08 %\n",
      "increasevolume 0.0003364256144777755 %\n",
      "decreasevolume 1.0589629173551884e-07 %\n",
      "increaseheat 1.4364825773327539e-06 %\n",
      "decreaseheat 5.9736004232036066e-05 %\n",
      "MAX: \n",
      "0.99999607\n",
      "0\n",
      "change languagenone\n",
      "\n",
      "Prediction for ./Train_Dataset_Truncated/15_deactivatelights.wav\n",
      "change languagenone 0.22138759959489107 %\n",
      "activatemusic 0.004535994230536744 %\n",
      "deactivatelights 37.21541464328766 %\n",
      "increasevolume 20.413024723529816 %\n",
      "decreasevolume 39.94375467300415 %\n",
      "increaseheat 0.19499043701216578 %\n",
      "decreaseheat 2.0068882033228874 %\n",
      "MAX: \n",
      "0.39943755\n",
      "4\n",
      "decreasevolume\n",
      "\n",
      "Prediction for ./Train_Dataset_Truncated/113_increasevolume.wav\n",
      "change languagenone 7.916805405683291e-09 %\n",
      "activatemusic 4.833198945231043e-10 %\n",
      "deactivatelights 2.5576694095974517e-07 %\n",
      "increasevolume 99.99988079071045 %\n",
      "decreasevolume 0.00010401920462754788 %\n",
      "increaseheat 8.885478308684469e-06 %\n",
      "decreaseheat 4.180896601146955e-09 %\n",
      "MAX: \n",
      "0.9999988\n",
      "3\n",
      "increasevolume\n",
      "\n",
      "Prediction for ./Train_Dataset_Truncated/151_increasevolume.wav\n",
      "change languagenone 4.049127163121072e-12 %\n",
      "activatemusic 4.1701123577681877e-16 %\n",
      "deactivatelights 1.5164202751561892e-19 %\n",
      "increasevolume 99.98669624328613 %\n",
      "decreasevolume 0.013299651618581265 %\n",
      "increaseheat 5.320445473078195e-09 %\n",
      "decreaseheat 1.92045337965574e-10 %\n",
      "MAX: \n",
      "0.99986696\n",
      "3\n",
      "increasevolume\n",
      "\n",
      "Prediction for ./Train_Dataset_Truncated/212_increaseheat.wav\n",
      "change languagenone 2.6604864977741727e-07 %\n",
      "activatemusic 3.5267768523292164e-11 %\n",
      "deactivatelights 7.810840737118238e-14 %\n",
      "increasevolume 1.9420478558629384e-07 %\n",
      "decreasevolume 3.1636474689955563e-09 %\n",
      "increaseheat 97.76195287704468 %\n",
      "decreaseheat 2.238047309219837 %\n",
      "MAX: \n",
      "0.9776195\n",
      "5\n",
      "increaseheat\n",
      "\n",
      "Prediction for ./AudioFiles/1678717382.0476763.wav\n",
      "change languagenone 99.99955892562866 %\n",
      "activatemusic 1.600975712154919e-16 %\n",
      "deactivatelights 1.1179315538407627e-13 %\n",
      "increasevolume 1.846004801114593e-12 %\n",
      "decreasevolume 0.0004290874585421989 %\n",
      "increaseheat 1.3724486491064453e-13 %\n",
      "decreaseheat 1.6297845206736383e-05 %\n",
      "MAX: \n",
      "0.9999956\n",
      "0\n",
      "change languagenone\n",
      "\n",
      "Prediction for ./AudioFiles/1678717386.5524414.wav\n",
      "change languagenone 99.84760880470276 %\n",
      "activatemusic 1.3837880697537518e-12 %\n",
      "deactivatelights 8.703173598467728e-09 %\n",
      "increasevolume 4.648776155136147e-05 %\n",
      "decreasevolume 0.15234040329232812 %\n",
      "increaseheat 1.459733484261705e-11 %\n",
      "decreaseheat 1.0510127490537258e-09 %\n",
      "MAX: \n",
      "0.9984761\n",
      "0\n",
      "change languagenone\n",
      "\n",
      "Prediction for ./AudioFiles/1678717391.0566754.wav\n",
      "change languagenone 2.817101590335369 %\n",
      "activatemusic 4.3769817685643947e-13 %\n",
      "deactivatelights 0.00012196785519336117 %\n",
      "increasevolume 0.004744378384202719 %\n",
      "decreasevolume 97.17794060707092 %\n",
      "increaseheat 2.356808671832855e-09 %\n",
      "decreaseheat 8.044523838179884e-05 %\n",
      "MAX: \n",
      "0.9717794\n",
      "4\n",
      "decreasevolume\n",
      "\n",
      "Prediction for ./AudioFiles/1678717395.5633824.wav\n",
      "change languagenone 0.008163378515746444 %\n",
      "activatemusic 1.551426630393149e-10 %\n",
      "deactivatelights 4.2803414146419527e-07 %\n",
      "increasevolume 0.00010130453347301227 %\n",
      "decreasevolume 99.8506486415863 %\n",
      "increaseheat 1.0164608044149759e-07 %\n",
      "decreaseheat 0.14107320457696915 %\n",
      "MAX: \n",
      "0.9985065\n",
      "4\n",
      "decreasevolume\n",
      "\n",
      "Prediction for ./AudioFiles/1678717400.0677488.wav\n",
      "change languagenone 89.72854614257812 %\n",
      "activatemusic 1.555599538072272e-08 %\n",
      "deactivatelights 7.880868180265566e-09 %\n",
      "increasevolume 0.000354428993887268 %\n",
      "decreasevolume 2.511926554143429 %\n",
      "increaseheat 5.045569082540169e-05 %\n",
      "decreaseheat 7.759114354848862 %\n",
      "MAX: \n",
      "0.89728546\n",
      "0\n",
      "change languagenone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test area\")\n",
    "def callback(indata, frames, callback_time, status):\n",
    "    \"\"\"This is called (from a separate thread) for each audio block.\"\"\"\n",
    "    timestamp = time()\n",
    "    # print(is_silence(indata))\n",
    "    # print(type(indata))  # Type is numpy.ndarray\n",
    "    \n",
    "    print(\"Noise!\")\n",
    "    write(f'./{args.output_directory}/{timestamp}.wav', args.resolution, indata)\n",
    "    filesize_in_bytes = os.path.getsize(f'./{args.output_directory}/{timestamp}.wav')\n",
    "    filesize_in_kb = filesize_in_bytes / 1024\n",
    "    print(f'Size: {filesize_in_kb:.2f}KB')\n",
    "\n",
    "# 10 fron on screen microphone\n",
    "# 14 from microphone nada?\n",
    "\n",
    "def test():\n",
    "    with sd.InputStream(device=args.device, channels=1, dtype='int16', samplerate=args.resolution, blocksize=blocksize, callback=callback):\n",
    "        while True:\n",
    "            key = input()\n",
    "            if key in ('q', 'Q'):\n",
    "                print('Stop recording.')\n",
    "                break\n",
    "                \n",
    "                \n",
    "filename1 = \"./Train_Dataset_Truncated/0_change languagenone.wav\"\n",
    "filename2 = \"./Train_Dataset_Truncated/15_deactivatelights.wav\"\n",
    "    \n",
    "    \n",
    "filename21 = \"./Train_Dataset_Truncated/113_increasevolume.wav\"\n",
    "filename22 = \"./Train_Dataset_Truncated/151_increasevolume.wav\"\n",
    "filename23 = \"./Train_Dataset_Truncated/212_increaseheat.wav\"\n",
    "    \n",
    "filename3 = \"./AudioFiles/1678717382.0476763.wav\"   \n",
    "filename4 = \"./AudioFiles/1678717386.5524414.wav\"\n",
    "filename5 = \"./AudioFiles/1678717391.0566754.wav\"\n",
    "filename6 = \"./AudioFiles/1678717395.5633824.wav\"  \n",
    "filename7 = \"./AudioFiles/1678717400.0677488.wav\" \n",
    "                \n",
    "def test2(filename):\n",
    "    print(\"Prediction for\",filename)\n",
    "    frame_length_in_s = 0.04\n",
    "    frame_step_in_s   = frame_length_in_s\n",
    "    global state\n",
    "    audio_binary = tf.io.read_file(filename)\n",
    "    audio, sampling_rate = tf.audio.decode_wav(audio_binary)\n",
    "    audio = tf.squeeze(audio, axis=-1) #all our audio are mono, drop extra axis\n",
    "    \n",
    "    frame_length = int(frame_length_in_s * args.resolution)\n",
    "    frame_step = int(frame_step_in_s * args.resolution)\n",
    "    stft = tf.signal.stft(\n",
    "        audio,\n",
    "        frame_length=frame_length,\n",
    "        frame_step=frame_step,\n",
    "        fft_length=frame_length\n",
    "    )\n",
    "    \n",
    "    spectrogram = tf.abs(stft)\n",
    "    \n",
    "    mel_spectrogram = tf.matmul(spectrogram, linear_to_mel_weight_matrix)\n",
    "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, 0)  # batch axis\n",
    "    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, -1)  # channel axis\n",
    "    mfcss = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "    #print(\"Shape \",input_details[0])\n",
    "    interpreter.set_tensor(input_details[0]['index'], mfcss)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    print(\"change languagenone\",output[0][0]*100,\"%\")\n",
    "    print(\"activatemusic\",output[0][1]*100,\"%\")\n",
    "    print(\"deactivatelights\",output[0][2]*100,\"%\")\n",
    "    print(\"increasevolume\",output[0][3]*100,\"%\")\n",
    "    print(\"decreasevolume\",output[0][4]*100,\"%\")\n",
    "    print(\"increaseheat\",output[0][5]*100,\"%\")\n",
    "    print(\"decreaseheat\",output[0][6]*100,\"%\")\n",
    "    #print(\"nannan\",output[0][7]*100,\"%\")\n",
    "    \n",
    "    send_prediction_as_mqtt(output[0])\n",
    "\n",
    "\n",
    "#test()\n",
    "\n",
    "test2(filename1)\n",
    "test2(filename2)\n",
    "test2(filename21)\n",
    "test2(filename22)\n",
    "test2(filename23)\n",
    "test2(filename3)\n",
    "test2(filename4)\n",
    "test2(filename5)\n",
    "test2(filename6)\n",
    "test2(filename7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa8238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
