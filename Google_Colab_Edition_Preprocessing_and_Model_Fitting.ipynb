{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import of necessary parts for google drive"
      ],
      "metadata": {
        "id": "LIybt8lv4sju"
      },
      "id": "LIybt8lv4sju"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "t1BIlB1O6eQ8",
        "outputId": "401fa2ce-fdea-49ca-943e-11c58ad3590e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "t1BIlB1O6eQ8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "metadata": {
        "id": "Acu8TupveCFE"
      },
      "id": "Acu8TupveCFE",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/MyDrive/datasets/dsl_data/\")"
      ],
      "metadata": {
        "id": "to-3QVHj7uFP"
      },
      "id": "to-3QVHj7uFP",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "EcdlHyi67tOu",
        "outputId": "6aa66744-241f-4495-dc1e-e58a15f53cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EcdlHyi67tOu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio\t\t __MACOSX\t\t saved_models\n",
            "checkpoints\t models\t\t\t tensorboard_data\n",
            "development.csv  preprocessingGoogle.py  Test_Dataset_Truncated\n",
            "dsl_data.zip\t __pycache__\t\t Train_Dataset_Truncated\n",
            "evaluation.csv\t sample_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive"
      ],
      "metadata": {
        "id": "KRAfj_Gl62dK",
        "outputId": "855c1572-ef9a-462a-cc77-14579ebbb872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KRAfj_Gl62dK",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'drive/MyDrive': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary install of dep and import libraries"
      ],
      "metadata": {
        "id": "5shtlITI3HCT"
      },
      "id": "5shtlITI3HCT"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git > /dev/null\n",
        "#!rm ./requiremen*\n",
        "#!rm ./preprocessing*\n",
        "#!ls\n",
        "!pip install -r ipython psutil==5.9.2 sounddevice==0.4.5 scipy==1.9.1 redis==4.3.4 tensorflow==2.10.0 tensorflow-io==0.27.0 cherrypy==18.8.0 paho-mqtt==1.6.1 > /dev/null\n",
        "!pip install -r librosa tensorflow_model_optimization pandas keras tensorflow_io > /dev/null\n",
        "!pip install tensorflow[io] > /dev/null\n",
        "!pip install tensorflow_model_optimization > /dev/null\n",
        "!pip install pydub\n"
      ],
      "metadata": {
        "id": "wKL8ZIyG6rDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f57acc-2046-45ad-9fcc-0ecd40bedf17"
      },
      "id": "wKL8ZIyG6rDt",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'ipython'\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'librosa'\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.9.2 does not provide the extra 'io'\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "95a9c863",
      "metadata": {
        "id": "95a9c863"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import tensorflow as tf\n",
        "import random\n",
        "#import tensorflow_io as tfio\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import argparse as ap\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/datasets/dsl_data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8596efa2",
      "metadata": {
        "id": "8596efa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12ffb77-49c8-4543-a174-615161fb2965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Be sure to have tensorboard, this code will be commented in final release\n"
          ]
        }
      ],
      "source": [
        "!echo \"Be sure to have tensorboard, this code will be commented in final release\"\n",
        "#!tensorboard --logdir ../../datasets/dsl_data/tensorboard_data/ &"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip of archive"
      ],
      "metadata": {
        "id": "d6-1LOFkKaFd"
      },
      "id": "d6-1LOFkKaFd"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!unzip -nq ./dsl_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNRZRYvbKcya",
        "outputId": "89eeab89-a7e6-4c03-fce5-540af2960fc9"
      },
      "id": "qNRZRYvbKcya",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio\t\t __MACOSX\t\t saved_models\n",
            "checkpoints\t models\t\t\t tensorboard_data\n",
            "development.csv  preprocessingGoogle.py  Test_Dataset_Truncated\n",
            "dsl_data.zip\t __pycache__\t\t Train_Dataset_Truncated\n",
            "evaluation.csv\t sample_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzxQBYDlLl6f",
        "outputId": "62a4713b-6256-4498-fde7-d6b125aed93e"
      },
      "id": "lzxQBYDlLl6f",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio\t\t __MACOSX\t\t saved_models\n",
            "checkpoints\t models\t\t\t tensorboard_data\n",
            "development.csv  preprocessingGoogle.py  Test_Dataset_Truncated\n",
            "dsl_data.zip\t __pycache__\t\t Train_Dataset_Truncated\n",
            "evaluation.csv\t sample_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for finding optimal length of audio files"
      ],
      "metadata": {
        "id": "nNVJJQ8Qh42Q"
      },
      "id": "nNVJJQ8Qh42Q"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "\n",
        "folder_path = '../../datasets/dsl_data/audio'\n",
        "\n",
        "def scan_folder(folder):\n",
        "  duration_count = {}\n",
        "  for root, dirs, files in os.walk(folder):\n",
        "    for file in files:\n",
        "      if file.endswith(\".wav\"):\n",
        "        file_path = os.path.join(root, file)\n",
        "        audio = AudioSegment.from_wav(file_path)\n",
        "        duration = len(audio)\n",
        "        if duration in duration_count:\n",
        "          duration_count[duration] += 1\n",
        "        else:\n",
        "            duration_count[duration] = 1\n",
        "  return duration_count\n",
        "\n",
        "def create_dataframe(duration_count):\n",
        "  data = {\"Duration of audio file\": list(duration_count.keys()), \n",
        "            \"Number of audio files with that duration\": list(duration_count.values())}\n",
        "  df = pd.DataFrame(data)\n",
        "  df = df.sort_values(by='Number of audio files with that duration', ascending=False)\n",
        "  return df\n",
        "\n",
        "\n",
        "# find the percentage. The duration returned in second is the size that include 1-percentage inside\n",
        "\n",
        "def find_duration(folder_path, percentage_files=0.9):\n",
        "  duration_count = {}\n",
        "  for root, dirs, files in os.walk(folder_path):\n",
        "    for file in files:\n",
        "      if file.endswith(\".wav\"):\n",
        "        file_path = os.path.join(root, file)\n",
        "        #print(file_path)\n",
        "        audio = AudioSegment.from_wav(file_path)\n",
        "        duration = len(audio) / 1000 #convert from ms to sec\n",
        "        if duration in duration_count:\n",
        "          duration_count[duration] += 1\n",
        "        else:\n",
        "          duration_count[duration] = 1\n",
        "    total_files = sum(duration_count.values())\n",
        "    target_files = total_files * percentage_files\n",
        "    current_count = 0\n",
        "    for duration, count in sorted(duration_count.items()):\n",
        "      current_count += count\n",
        "      if current_count >= target_files:\n",
        "        duration = round(duration)\n",
        "        print(f\"Duration of audio that makes {percentage_files*100}% of the files have that duration is: {duration} seconds\")\n",
        "        return duration\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "duration = find_duration(folder_path)\n",
        "\n",
        "pathPreprocessing = \"../../datasets/dsl_data/preprocessingGoogle.py\"\n",
        "\n",
        "with open(pathPreprocessing, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Update the 4th line\n",
        "lines[8] = \"length_calculated = {}\\n\".format(duration)\n",
        "\n",
        "\n",
        "with open(pathPreprocessing, \"w\") as file:\n",
        "    file.writelines(lines)\n",
        "#print(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZsUS3bvh9X9",
        "outputId": "6be19214-3840-40ba-a5aa-aa0a435c5b01"
      },
      "id": "wZsUS3bvh9X9",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of audio that makes 90.0% of the files have that duration is: 4 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ../../datasets/dsl_data/preprocessingGoogle.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVX8oNgfxdji",
        "outputId": "ab45ec83-033e-4a9d-d098-b0ca706e2bc4"
      },
      "id": "ZVX8oNgfxdji",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import tensorflow as tf\n",
            "# import tensorflow_io as tfio\n",
            "import numpy as np\n",
            "LABELS = ['change languagenone', 'activatemusic', 'deactivatelights', 'increasevolume', 'decreasevolume', 'increaseheat', 'decreaseheat']\n",
            "# This is the file genarated that has the Labels that i must use for training\n",
            " \n",
            "frame_length_in_s = 0.032\n",
            "frame_step_in_s  = frame_length_in_s\n",
            "length_calculated = 4\n",
            "\n",
            "PREPROCESSING_ARGS = {\n",
            "    'downsampling_rate': 16000,\n",
            "    'frame_length_in_s': frame_length_in_s,\n",
            "    'frame_step_in_s': frame_step_in_s,\n",
            "}\n",
            "\n",
            "# TRAINING_ARGS = {\n",
            "#     'batch_size': 32,\n",
            "#     'initial_learning_rate': 0.03,\n",
            "#     'end_learning_rate': 0.001, #1.e-9,\n",
            "#     'epochs': 1\n",
            "# }\n",
            "\n",
            "\n",
            "final_sparsity = 0.01\n",
            "\n",
            "num_mel_bins = (int) ((16000 - 16000 * PREPROCESSING_ARGS['frame_length_in_s'])/(16000*PREPROCESSING_ARGS['frame_step_in_s']))+1\n",
            "print(num_mel_bins)\n",
            "\n",
            "PREPROCESSING_ARGS = {\n",
            "    **PREPROCESSING_ARGS,\n",
            "    'num_mel_bins': num_mel_bins,\n",
            "    'lower_frequency': 80,\n",
            "    'upper_frequency': 8000,\n",
            "}\n",
            "\n",
            "downsampling_rate = PREPROCESSING_ARGS['downsampling_rate']\n",
            "sampling_rate_int64 = tf.cast(downsampling_rate, tf.int64)\n",
            "frame_length = int(downsampling_rate * PREPROCESSING_ARGS['frame_length_in_s'])\n",
            "print(\"Frame_length: {}\".format(frame_length))\n",
            "frame_step = int(downsampling_rate * PREPROCESSING_ARGS['frame_step_in_s'])\n",
            "print(\"Frame_length: {}\".format(frame_step))\n",
            "num_spectrogram_bins = frame_length // 2 + 1\n",
            "num_mel_bins = PREPROCESSING_ARGS['num_mel_bins']\n",
            "lower_frequency = PREPROCESSING_ARGS['lower_frequency']\n",
            "upper_frequency = PREPROCESSING_ARGS['upper_frequency']\n",
            "\n",
            "linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
            "    num_mel_bins=num_mel_bins,\n",
            "    num_spectrogram_bins=num_spectrogram_bins,\n",
            "    sample_rate=downsampling_rate,\n",
            "    lower_edge_hertz=lower_frequency,\n",
            "    upper_edge_hertz=upper_frequency\n",
            ")\n",
            "\n",
            "def preprocess(filename):\n",
            "    audio_binary = tf.io.read_file(filename)\n",
            "\n",
            "    path_parts = tf.strings.split(filename, '_')\n",
            "    path_end = path_parts[-1]\n",
            "    file_parts = tf.strings.split(path_end, '.')\n",
            "    true_label = file_parts[0]\n",
            "    label_id = tf.argmax(true_label == LABELS)\n",
            "    audio, sampling_rate = tf.audio.decode_wav(audio_binary)\n",
            "    audio = tf.squeeze(audio, axis=-1) #all our audio are mono, drop extra axis\n",
            "    audio_padded = audio\n",
            "    stft = tf.signal.stft(\n",
            "        audio,\n",
            "        frame_length=frame_length,\n",
            "        frame_step=frame_step,\n",
            "        fft_length=frame_length\n",
            "    )\n",
            "    spectrogram = tf.abs(stft)\n",
            "    mel_spectrogram = tf.matmul(spectrogram, linear_to_mel_weight_matrix)\n",
            "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
            "    log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, -1)  # channel axis\n",
            "    mfcss = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
            "\n",
            "    return mfcss, label_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b824503",
      "metadata": {
        "id": "8b824503"
      },
      "source": [
        " # Preprocessing for Train dataset files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4da2cb4f",
      "metadata": {
        "id": "4da2cb4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b323ba6e-8238-45b3-cc62-a995572b4a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n",
            "Frame_length: 512\n",
            "Frame_length: 512\n"
          ]
        }
      ],
      "source": [
        "import preprocessingGoogle as pr\n",
        "# process_file better to be implemented here with a boolean value that checks if i am processing train_dataset or eval file\n",
        "def process_file(file_path, flag):\n",
        "    file_path_exists = df[df[\"path\"] == file_path].shape[0] > 0 #flag\n",
        "    if file_path_exists:\n",
        "        new_sr=16000\n",
        "        # identifier care\n",
        "        identifier = df.loc[df[\"path\"] == file_path, \"Id\"].values[0]\n",
        "        identifier = str(int(identifier))\n",
        "        # label constructor\n",
        "        label = \"\"\n",
        "        if flag == 1:\n",
        "            label  += \"_\"\n",
        "            action  = df.loc[df[\"path\"] == file_path, \"action\"].values[0]\n",
        "            object  = df.loc[df[\"path\"] == file_path, \"object\"].values[0]\n",
        "            label  += action + object\n",
        "        # If no label available, code will just go on\n",
        "        new_file_path = os.path.join(new_folder_path, identifier + label + '.wav')\n",
        "        y, sr = librosa.load('../../datasets/'+file_path)\n",
        "        y_truncated = librosa.effects.trim(y, top_db=50, frame_length=2048, hop_length=512, ref=np.max)[0]\n",
        "        y_truncated = librosa.resample(y_truncated, orig_sr=sr, target_sr=new_sr)\n",
        "        y_truncated = y_truncated[:int(pr.length_calculated*new_sr)] #if longer\n",
        "        target_length = pr.length_calculated * new_sr\n",
        "        y_truncated = librosa.util.fix_length(data=y_truncated, size=target_length) # padding, if shorter\n",
        "        sf.write(new_file_path, y_truncated, new_sr, 'PCM_16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "acdacf47",
      "metadata": {
        "scrolled": true,
        "id": "acdacf47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c5b5b4-9a64-4ed9-9d48-c4023fd5ef54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution ended\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../../datasets/dsl_data/development.csv', sep=',')\n",
        "new_folder_path = '../../datasets/dsl_data/Train_Dataset_Truncated/'\n",
        "\n",
        "folder_path = '../../datasets/dsl_data/'\n",
        "\n",
        "if not os.path.isdir(new_folder_path):\n",
        "  os.makedirs(new_folder_path) # hoping to have write permissions set\n",
        "if not os.listdir(new_folder_path):\n",
        "  with ThreadPoolExecutor() as executor: # who is your single threaddy?\n",
        "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
        "      dirpath = dirpath.replace(\"\\\\\", \"/\")\n",
        "      dirpath = dirpath[dirpath.index(\"/\")+1:] # FUCK MICROSOFT AND FUCK THE FUCKING IDEA OF \n",
        "      dirpath = dirpath[dirpath.index(\"/\")+1:] # FUCKING USING \\ FOR PATH!!!!!!!!!!111oneone!!1!!!\n",
        "      dirpath = dirpath[dirpath.index(\"/\")+1:]\n",
        "      for filename in filenames:\n",
        "        file_path = os.path.join(dirpath, filename)\n",
        "        file_path = file_path.replace(\"\\\\\", \"/\")\n",
        "        executor.submit(process_file, file_path, 1)\n",
        "# print(df)\n",
        "print(\"Execution ended\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f2ef26e",
      "metadata": {
        "id": "8f2ef26e"
      },
      "source": [
        " # Preprocessing for Evaluation dataset files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "66b4ba13",
      "metadata": {
        "id": "66b4ba13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92819311-cf53-4021-e7c2-6454933cee49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution ended\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('../../datasets/dsl_data/evaluation.csv', sep=',')\n",
        "new_folder_path = '../../datasets/dsl_data/Test_Dataset_Truncated/'\n",
        "folder_path = '../../datasets/dsl_data/'\n",
        "\n",
        "if not os.path.isdir(new_folder_path):\n",
        "    os.makedirs(new_folder_path)\n",
        "\n",
        "if not os.listdir(new_folder_path):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for dirpath, dirnames, filenames in os.walk(folder_path):\n",
        "            dirpath = dirpath.replace(\"\\\\\", \"/\")\n",
        "            dirpath = dirpath[dirpath.index(\"/\")+1:]\n",
        "            dirpath = dirpath[dirpath.index(\"/\")+1:]\n",
        "            dirpath = dirpath[dirpath.index(\"/\")+1:]\n",
        "            for filename in filenames:\n",
        "                file_path = os.path.join(dirpath, filename)\n",
        "                file_path = file_path.replace(\"\\\\\", \"/\")\n",
        "                executor.submit(process_file, file_path, 0)\n",
        "\n",
        "print(\"Execution ended\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69c41b90",
      "metadata": {
        "id": "69c41b90"
      },
      "source": [
        "# Auto - updating labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c0749be3",
      "metadata": {
        "id": "c0749be3"
      },
      "outputs": [],
      "source": [
        "pathPreprocessing = \"../../datasets/dsl_data/preprocessingGoogle.py\"\n",
        "\n",
        "df = pd.read_csv('../../datasets/dsl_data/development.csv', sep=',')\n",
        "df['labels'] = df['action'].astype(str) + df['object'].astype(str)\n",
        "distinct_values = df['labels'].unique()\n",
        "\n",
        "result = 'LABELS = ['\n",
        "for value in distinct_values:\n",
        "    result += \"'\" + str(value) + \"', \"\n",
        "\n",
        "result = result[:-2] + ']\\n' # lazy workaround, the last label has a comma that is bad.. this is also bad.\n",
        "\n",
        "with open(pathPreprocessing, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Update the 4th line\n",
        "lines[3] = result\n",
        "lines[4] = \"# This is the file genarated that has the Labels that i must use for training\\n\"\n",
        "\n",
        "with open(pathPreprocessing, \"w\") as file:\n",
        "    file.writelines(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c5a54e",
      "metadata": {
        "id": "18c5a54e"
      },
      "source": [
        "# Model creation and fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a5698194",
      "metadata": {
        "id": "a5698194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e050c9d0-6eb3-4205-f224-b016338fa588"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--eval_percentage'], dest='eval_percentage', nargs=None, const=None, default=0.15, type=<class 'float'>, choices=None, help='Choosing eval_percentage', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "parser = ap.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--batch_size', default=32, type=int, help=\"Choosing batch size default is 32\")\n",
        "parser.add_argument('--initial_learning_rate', default=0.03, type=float, help=\"Choosing initial_learning_rate\")\n",
        "parser.add_argument('--end_learning_rate', default=0.001, type=float, help=\"Choosing end_learning_rate\")\n",
        "parser.add_argument('--epochs', default=50, type=int, help=\"Choosing epochs\")\n",
        "parser.add_argument('--test_percentage', default=0.2, type=float, help=\"Choosing test_percentage\")\n",
        "parser.add_argument('--pruning_initial_step', default=0.2, type=float, help=\"Choosing pruning_initial_step\")\n",
        "parser.add_argument('--initial_sparsity', default=0.40, type=float, help=\"Choosing initial_sparsity\")\n",
        "parser.add_argument('--alpha', default=1, type=float, help=\"Choosing alpha\")\n",
        "\n",
        "parser.add_argument('--eval_percentage', default=0.15, type=float, help=\"Choosing eval_percentage\")\n",
        "#,'--eval_percentage','0.0'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5355da28",
      "metadata": {
        "id": "5355da28"
      },
      "source": [
        "Parser arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0cbb23f1",
      "metadata": {
        "id": "0cbb23f1"
      },
      "outputs": [],
      "source": [
        "args = parser.parse_args(['--epochs','100','--batch_size','128','--pruning_initial_step','0.9','--initial_learning_rate','0.03','--end_learning_rate','0.001','--alpha','0.25'])\n",
        "# args = parser.parse_args()\n",
        "num_units = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169533d1",
      "metadata": {
        "id": "169533d1"
      },
      "source": [
        "## This part of the code exist to manage all the folders\n",
        "## Please be careful, if the directories tree is not respected, the code will not work properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3c6a22f4",
      "metadata": {
        "id": "3c6a22f4"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "795af38c",
      "metadata": {
        "id": "795af38c"
      },
      "outputs": [],
      "source": [
        "# Useful to save tensorboard data\n",
        "log_dir_tensorboard = '../../datasets/dsl_data/tensorboard_data/'\n",
        "if not os.path.isdir(log_dir_tensorboard):\n",
        "    os.makedirs(log_dir_tensorboard)\n",
        "#runs = [int(d.split('_')[1]) for d in os.listdir(log_dir_tensorboard) if 'run_' in d]\n",
        "#tb_run = max(runs) + 1 if runs else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6c7ef7f6",
      "metadata": {
        "id": "6c7ef7f6"
      },
      "outputs": [],
      "source": [
        "# Folder creation\n",
        "train_ds_location      = '../../datasets/dsl_data/Train_Dataset_Truncated/'\n",
        "log_dir_model          = '../../datasets/dsl_data/models/'\n",
        "#run_{}_\n",
        "model_name             = 'epochs_{}_batch_size_{}_pruning_initial_step_{}_initial_learning_rate_{}_end_learning_rate_{}_test_percentage_{}_pruning_initial_step_{}_initial_sparsity_{}_alpha_{}'.format(args.epochs,args.batch_size,args.pruning_initial_step,args.initial_learning_rate,args.end_learning_rate,args.test_percentage,args.pruning_initial_step,args.initial_sparsity,args.alpha)\n",
        "checkpoint_path        = '../../datasets/dsl_data/checkpoints/' + model_name\n",
        "#check_point_file_name  = checkpoint_path+'.ckpt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a1c4d4b9",
      "metadata": {
        "id": "a1c4d4b9"
      },
      "outputs": [],
      "source": [
        "# If folders to not exist -> create them\n",
        "# This code will not check for the dataset folders, the code above must be executed\n",
        "if not os.path.isdir(log_dir_model):\n",
        "    os.makedirs(log_dir_model)\n",
        "if not os.path.isdir(checkpoint_path):\n",
        "    os.makedirs(checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb853db5",
      "metadata": {
        "id": "bb853db5"
      },
      "source": [
        " # Obtaining Test data from train data, using shuffle and avoiding retaking same data on different runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "2bf47be3",
      "metadata": {
        "id": "2bf47be3"
      },
      "outputs": [],
      "source": [
        "file_paths = []\n",
        "\n",
        "for filename in os.listdir(train_ds_location):\n",
        "    file_path = os.path.join(train_ds_location, filename)\n",
        "    file_paths.append(file_path)\n",
        "random.shuffle(file_paths)\n",
        "num_test_files = int(len(file_paths) * args.test_percentage)\n",
        "num_eval_files = int(len(file_paths) * args.eval_percentage)\n",
        "#not using eval dataset\n",
        "\n",
        "\n",
        "# num_eval_files = num_eval_files\n",
        "\n",
        "# it is shuffled, so i can do this\n",
        "test_paths     = file_paths[:num_test_files]                 # from 0 to num_test_files\n",
        "#train_paths    = file_paths[num_test_files:]\n",
        "train_paths    = file_paths[num_test_files:-num_eval_files]  # from num_test_files to end-num_eval_files\n",
        "eval_paths     = file_paths[-num_eval_files:]                # until the end\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_paths))\n",
        "print(len(test_paths))\n",
        "print(len(eval_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn1FluvO5Opv",
        "outputId": "592c21a8-09c4-4574-b609-52b75fd36b4c"
      },
      "id": "Qn1FluvO5Opv",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6406\n",
            "1970\n",
            "1478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b36277",
      "metadata": {
        "id": "d8b36277"
      },
      "source": [
        "# Preprocessing data and model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b8ed3736",
      "metadata": {
        "id": "b8ed3736",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce02ccb8-5179-4e6d-e0e3-4c78ac23b446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Shape: (128, 62, 31, 1)\n",
            "Data Shape: (62, 31, 1)\n",
            "Labels: tf.Tensor(\n",
            "[3 6 6 5 3 3 3 0 3 0 4 3 3 3 6 4 3 4 1 3 4 3 2 3 3 1 4 3 5 6 2 3 3 6 3 4 6\n",
            " 4 4 2 3 6 3 0 3 3 4 6 3 5 2 6 3 0 0 6 3 4 4 4 3 4 6 6 3 3 5 5 4 0 1 4 2 3\n",
            " 4 3 6 3 3 1 3 3 1 6 3 4 1 6 6 4 4 5 0 5 0 3 0 3 3 5 3 5 0 4 0 1 6 4 3 4 0\n",
            " 3 3 6 2 4 0 1 4 4 3 6 4 3 4 6 6 5], shape=(128,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "train_ds       = tf.data.Dataset.list_files(train_paths)\n",
        "val_ds         = tf.data.Dataset.list_files(eval_paths)\n",
        "test_ds        = tf.data.Dataset.list_files(test_paths)\n",
        "\n",
        "train_ds       = train_ds.map(pr.preprocess).batch(args.batch_size).cache()\n",
        "val_ds         = val_ds.map(pr.preprocess).batch(args.batch_size)\n",
        "test_ds        = test_ds.map(pr.preprocess).batch(args.batch_size)\n",
        "\n",
        "for example_batch, example_labels in train_ds.take(1):\n",
        "  print('Batch Shape:', example_batch.shape)\n",
        "  print('Data Shape:', example_batch.shape[1:])\n",
        "  print('Labels:', example_labels)\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "begin_step          = int(len(train_ds) * args.epochs * args.pruning_initial_step)\n",
        "end_step            = int(len(train_ds) * args.epochs)\n",
        "pruning_params      = {\n",
        "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
        "        initial_sparsity=args.initial_sparsity,\n",
        "        final_sparsity=pr.final_sparsity,\n",
        "        begin_step=begin_step,\n",
        "        end_step=end_step\n",
        "    )\n",
        "}\n",
        "custom_objects      = {'PruneLowMagnitude': prune_low_magnitude}\n",
        "\n",
        "# model_name          = 'model_'+str(args.batch_size)+'_'+str(args.alpha)\n",
        "# model_name += '.h5'\n",
        "\n",
        "hparams = {\n",
        "'num_units' : num_units,\n",
        "'alpha_rate': args.alpha,\n",
        "'epochs'    : args.epochs,\n",
        "'batch_size': args.batch_size,\n",
        "}\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n",
        "    tf.keras.layers.Conv2D(filters=int(num_units * args.alpha), kernel_size=[3, 3], strides=[2, 2],\n",
        "        use_bias=False, padding='valid'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(filters=int(num_units * args.alpha), kernel_size=[3, 3], strides=[1, 1],\n",
        "            use_bias=False, padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(filters=int(num_units * args.alpha), kernel_size=[3, 3], strides=[1, 1],\n",
        "        use_bias=False, padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(units=len(pr.LABELS)),\n",
        "    tf.keras.layers.Softmax()\n",
        "    ])\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "eb8ec704",
      "metadata": {
        "id": "eb8ec704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43655c55-206c-4d9b-88f2-d559d3a0c2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(62, 31, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d   (None, 30, 15, 128)      2306      \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_n  (None, 30, 15, 128)      513       \n",
            " ormalization (PruneLowMagni                                     \n",
            " tude)                                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu (  (None, 30, 15, 128)      1         \n",
            " PruneLowMagnitude)                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 30, 15, 128)      294914    \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_n  (None, 30, 15, 128)      513       \n",
            " ormalization_1 (PruneLowMag                                     \n",
            " nitude)                                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_1  (None, 30, 15, 128)      1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 30, 15, 128)      294914    \n",
            " 2 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_batch_n  (None, 30, 15, 128)      513       \n",
            " ormalization_2 (PruneLowMag                                     \n",
            " nitude)                                                         \n",
            "                                                                 \n",
            " prune_low_magnitude_re_lu_2  (None, 30, 15, 128)      1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_global_  (None, 128)              1         \n",
            " average_pooling2d (PruneLow                                     \n",
            " Magnitude)                                                      \n",
            "                                                                 \n",
            " prune_low_magnitude_dense (  (None, 7)                1801      \n",
            " PruneLowMagnitude)                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_softmax  (None, 7)                1         \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 595,479\n",
            "Trainable params: 297,735\n",
            "Non-trainable params: 297,744\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# this model uses Transfer Learning... I mean, we transferred a model developed for another course to this course\n",
        "print(example_batch.shape[1:])\n",
        "model_for_pruning.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model fitting"
      ],
      "metadata": {
        "id": "dSA36b8J31Um"
      },
      "id": "dSA36b8J31Um"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b35a1c",
      "metadata": {
        "scrolled": true,
        "id": "69b35a1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c6f082-b4ab-4294-d9f0-c7d634a02e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No previous check_point found.\n",
            "Epoch 1/100\n"
          ]
        }
      ],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate=args.initial_learning_rate,\n",
        "    end_learning_rate=args.end_learning_rate,\n",
        "    decay_steps=len(train_ds) * args.epochs,\n",
        ")\n",
        "optimizer = tf.optimizers.Adam(learning_rate=linear_decay)\n",
        "metrics = [tf.metrics.SparseCategoricalAccuracy()]\n",
        "\n",
        "callbacks = [ tf.keras.callbacks.ModelCheckpoint(filepath=log_dir_tensorboard+model_name,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1),\n",
        "             tfmot.sparsity.keras.UpdatePruningStep(), \n",
        "             keras.callbacks.TensorBoard(log_dir=log_dir_tensorboard+model_name, histogram_freq=1) , hp.KerasCallback(log_dir_tensorboard+model_name, hparams),\n",
        "             ]\n",
        "\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "if os.path.exists(log_dir_tensorboard+model_name+'.ckpt'):\n",
        "    print(\"Checkpoint found, loading...\")\n",
        "    model.load_weights(log_dir_tensorboard+model_name+'.ckpt')\n",
        "    with open(log_dir_tensorboard+model_name+\"epochs.txt\", \"r\") as file:\n",
        "        contents = file.read()\n",
        "        previous_epoch_run = int(contents)\n",
        "        previous_epoch_run = previous_epoch_run\n",
        "    print(\"Restoring from epoch : {}\".format(previous_epoch_run))\n",
        "else:\n",
        "    print(\"No previous check_point found.\")\n",
        "    previous_epoch_run = 0\n",
        "\n",
        "#validation data is test_ds validation_data=val_ds,\n",
        "    \n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=args.epochs, callbacks=callbacks,verbose=1,initial_epoch=previous_epoch_run) #it was valds\n",
        "\n",
        "with open(log_dir_tensorboard+model_name+\"epochs.txt\", \"w\") as file:\n",
        "    file.write(str(args.epochs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab63e37",
      "metadata": {
        "id": "eab63e37"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "\n",
        "training_loss = history.history['loss'][-1]\n",
        "training_accuracy = history.history['sparse_categorical_accuracy'][-1]\n",
        "val_loss = history.history['val_loss'][-1]\n",
        "val_accuracy = history.history['val_sparse_categorical_accuracy'][-1]\n",
        "\n",
        "print(f'Training Loss: {training_loss:.4f}')\n",
        "print(f'Training Accuracy: {training_accuracy*100.:.2f}%')\n",
        "print()\n",
        "print(f'Validation Loss: {val_loss:.4f}')\n",
        "print(f'Validation Accuracy: {val_accuracy*100.:.2f}%')\n",
        "print()\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy*100.:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a63692d0",
      "metadata": {
        "id": "a63692d0"
      },
      "outputs": [],
      "source": [
        "with open(log_dir_model+model_name+\".txt\", \"w\") as file:\n",
        "    file.write(model_name)\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"Execution lasted: \" + str(args.epochs))\n",
        "    file.write(\"\\n\")\n",
        "    file.write(f'\\nTraining Loss: {training_loss:.4f}')\n",
        "    file.write(f'\\nTraining Accuracy: {training_accuracy*100.:.2f}%')\n",
        "    file.write(\"\\n\")\n",
        "    file.write(f'\\nValidation Loss: {val_loss:.4f}')\n",
        "    file.write(f'\\nValidation Accuracy: {val_accuracy*100.:.2f}%')\n",
        "    file.write(\"\\n\")\n",
        "    file.write(f'\\nTest Loss: {test_loss:.4f}')\n",
        "    file.write(f'\\nTest Accuracy: {test_accuracy*100.:.2f}%')\n",
        "    \n",
        "saved_model_dir = f'./saved_models/last_model_used'\n",
        "if not os.path.exists(saved_model_dir):\n",
        "    os.makedirs(saved_model_dir)\n",
        "model.save(saved_model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(log_dir_model+model_name)\n",
        "with open(log_dir_model+model_name+\".txt\", \"r\") as file:\n",
        "        contents = file.read()\n",
        "        print(contents)\n",
        "    "
      ],
      "metadata": {
        "id": "Ij00I6v5eHGV"
      },
      "id": "Ij00I6v5eHGV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LIybt8lv4sju",
        "5shtlITI3HCT",
        "d6-1LOFkKaFd",
        "nNVJJQ8Qh42Q",
        "8b824503",
        "8f2ef26e",
        "69c41b90",
        "169533d1",
        "bb853db5",
        "d8b36277"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}